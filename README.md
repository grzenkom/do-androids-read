# Do androids read about electric sheep? Machine reading comprehension algorithms

[![Code4Life logo](https://code4life.pl/assets/images/code4life-logo.png)](https://it.roche.pl/)

## Research papers

### Stanford Question Answering Dataset (SQuAD)

Papers: https://arxiv.org/pdf/1606.05250.pdf (2016), https://arxiv.org/pdf/1806.03822.pdf (2018)  
Website: https://rajpurkar.github.io/SQuAD-explorer/  
Leaderboard: see the main page of the website

### Reading Comprehension with Multiple Hops (QAnagaroo)

Paper: https://arxiv.org/pdf/1710.06481.pdf (2018)  
Website: https://qangaroo.cs.ucl.ac.uk/  
Leaderboard: https://qangaroo.cs.ucl.ac.uk/leaderboard.html

### NarrativeQA Reading Comprehension Challenge (NarrativeQA)

Paper: https://arxiv.org/pdf/1712.07040.pdf (2017)  
Website: https://github.com/deepmind/narrativeqa/  
Leaderboard: https://paperswithcode.com/sota/reading-comprehension-narrativeqa (unofficial)

### General Language Understanding Evaluation (GLUE)

Paper: https://arxiv.org/pdf/1804.07461.pdf (2019)  
Website: https://gluebenchmark.com/  
Leaderboard: https://gluebenchmark.com/leaderboard/

## Other sources

- [Reading comprehension definition](https://en.wikipedia.org/wiki/Reading_comprehension)
- [Similarity metrics (BLEU, METEOR, ROUGE)](https://medium.com/explorations-in-language-and-learning/metrics-for-nlg-evaluation-c89b6a781054)

## Recommended materials

### NLP websites

The following websites aggregate latest research papers and datasets, grouped by NLP tasks:

- [NLP Progress](http://nlpprogress.com/)
- [Modern Deep Learning Techniques Applied to NLP](https://nlpoverview.com/)
- [Papers With Code - NLP](https://paperswithcode.com/area/natural-language-processing)

### Videos

- [Yoav Goldberg: The missing elements in NLP (spaCy IRL 2019)](https://youtu.be/e12danHhlic)
- [Mark Neumann: ScispaCy: A spaCy pipeline & models for scientific & biomedical text (spaCy IRL 2019)](https://youtu.be/2_HSKDALwuw)
- [Peter Baumgartner: Applied NLP: Lessons from the Field (spaCy IRL 2019)](https://youtu.be/QRGMJWwOU94)

### AI skepticism

[Machines Beat Humans on a Reading Test. But Do They Understand?](https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/)

> But is AI actually starting to understand our language — or is it just getting better
> at gaming our systems? As BERT-based neural networks have taken benchmarks like GLUE
> by storm, new evaluation methods have emerged that seem to paint these powerful NLP
> systems as computational versions of Clever Hans, the early 20th-century horse who
> seemed smart enough to do arithmetic, but who was actually just following unconscious
> cues from his trainer.

[Why A.I. is a big fat lie](https://bigthink.com/technology-innovation/why-a-i-is-a-big-fat-lie)

> (...) we have very little insight into how our brains pull off what they pull off.
> Replicating a brain neuron-by-neuron is a science fiction "what if" pipe dream.
> And introspection – when you think about how you think – is interesting, big time,
> but ultimately tells us precious little about what's going on in there.

> Your common sense is more amazing – and unachievable – than your common sense can
> sense. You're amazing. Your ability to think abstractly and "understand" the world
> around you might feel simple in your moment-to-moment experience, but it's incredibly
> complex. That experience of simplicity is either a testament to how adept your
> uniquely human brain is or a great illusion that's intrinsic to the human
> condition – or probably both.

> The trick is to take a moment to think about this difference. Our own personal experiences
> of being one of those smart creatures called a human is what catches us in a thought trap.
> Our very particular and very impressive capabilities are hidden from ourselves beneath
> a veil of a conscious experience that just kind of feels like "clarity." It feels simple,
> but under the surface, it's oh so complex. Replicating our "general common sense" is
> a fanciful notion that no technological advancements have ever moved us towards in any
> meaningful way.

[DeepMind's Losses and the Future of Artificial Intelligence](https://www.wired.com/story/deepminds-losses-future-artificial-intelligence/)

> Researchers in machine learning now often ask, “How can machines optimize complex problems
> using massive amounts of data?” We might also ask, “How do children acquire language and
> come to understand the world, using less power and data than current AI systems do?” If
> we spent more time, money, and energy on the latter question than the former, we might
> get to artificial general intelligence a lot sooner.

[Deep Learning: A Critical Appraisal](https://arxiv.org/pdf/1801.00631v1.pdf)

> What exactly is deep learning, and what has its shown about the nature of intelligence?
> What can we expect it to do, and where might we expect it to break down? How close or
> far are we from “artificial general intelligence”, and a point at which machines show a
> human-like flexibility in solving unfamiliar problems? The purpose of this paper is both
> to temper some irrational exuberance and also to consider what we as a field might need
> to move forward.

#### AI in healthcare

[How IBM Watson Overpromised and Underdelivered on AI Health Care](https://spectrum.ieee.org/biomedical/diagnostics/how-ibm-watson-overpromised-and-underdelivered-on-ai-health-care)

> In many attempted applications, Watson’s NLP struggled to make sense of medical text—as
> have many other AI systems. “We’re doing incredibly better with NLP than we were five years
> ago, yet we’re still incredibly worse than humans,” says Yoshua Bengio, a professor of
> computer science at the University of Montreal and a leading AI researcher. **In medical
> text documents, Bengio says, AI systems can’t understand ambiguity and don’t pick up on
> subtle clues that a human doctor would notice.** Bengio says current NLP technology can
> help the health care system: "It doesn’t have to have full understanding to do something
> incredibly useful," he says. But no AI built so far can match a human doctor’s comprehension
> and insight. "No, we’re not there," he says.

> Watson learned fairly quickly how to scan articles about clinical studies and determine
> the basic outcomes. **But it proved impossible to teach Watson to read the articles 
> the way a doctor would.** "The information that physicians extract from an article, that
> they use to change their care, may not be the major point of the study," Kris says.
> Watson’s thinking is based on statistics, so all it can do is gather statistics about
> main outcomes, explains Kris. "But doctors don’t work that way."

[AI And Healthcare: Is The Bloom Finally Off The Rose?](https://www.forbes.com/sites/davidshaywitz/2019/08/23/ai-and-healthcare-is-the-bloom-finally-off-the-rose/amp/)

> Bender goes on to also point out that many of the so-called early successes around
> "AI in drug discovery" are important but also "a good number of steps away from the more
> difficult biological and in vivo stages, where efficacy and toxicity in living organisms
> decides the fate of drugs waiting to be discovered. Hence, there is still a gap that
> needs to be bridged…"
>
> The key issue, he concludes, is the need for "sufficient and sufficiently relevant data
> in order to predict properties of potential therapies that are relevant for the in vivo
> situation, which are related to efficacy and toxicity-relevant endpoints."

## Viewing the notebook online

Generally, GitHub is able to render Jupyter notebooks, so just click the file `nlp_demo.ipynb`
first. If it fails (probably with a generic error like `Sorry, something went wrong. Reload?`),
you have two options:

1. view the notebook saved in different formats in directory [/exported](/exported),
2. use another _nbviewer_ server, e.g.
   [nlp_demo.ipynb @ nbviewer.jupyter.org](https://nbviewer.jupyter.org/github/grzenkom/do-androids-read/blob/master/nlp_demo.ipynb).

## Running the notebook

Check [NOTES.md](NOTES.md) for hints to run the notebook locally or use
[Binder](https://mybinder.org/) to deploy it to the cloud.

[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/grzenkom/do-androids-read/master?filepath=nlp_demo.ipynb)

It may take Binder 10-15 minutes to download all the dependencies and build the Docker image
for the project (but it's amazing to watch it happen in a browser window).
